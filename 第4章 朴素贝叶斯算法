'''
一、基础知识
1 准备知识：条件概率公式

相信学过概率论的同学对于概率论绝对不会陌生，如果一时觉得生疏，可以查阅相关资料，在这里主要是想贴出条件概率的计算公式：
　　P(A|B)=P(A,B)/P(B)=P(B|A)*P(A)/P(B)
2 如何使用条件概率进行分类
　　假设这里要被分类的类别有两类，类c1和类c2，那么我们需要计算概率p(c1|x,y)和p(c2|x,y)的大小并进行比较：
如果：p(c1|x,y)>p(c2|x,y),则(x,y)属于类c1
     p(c1|x,y)<p(c2|x,y),则(x,y)属于类c2
我们知道p(x,y|c)的条件概率所表示的含义为：已知类别c1条件下，取到点(x，y)的概率；那么p(c1|x,y)所要表达的含义呢？显然，我们同样可以按照条件概率的方法来对概率含义进行描述，即在给定点(x,y)的条件下，求该点属于类c1的概率值。那么这样的概率该如何计算呢？显然，我们可以利用贝叶斯准则来进行变换计算：
　　p(ci|x,y)=p(x,y|ci)*p(ci)/p(x,y)
利用上面的公式，我们可以计算出在给定实例点的情况下，分类计算其属于各个类别的概率，然后比较概率值，选择具有最大概率的那么类作为点(x,y)的预测分类结果。
　　以上我们知道了通过贝叶斯准则来计算属于各个分类的概率值，那么具体而言，就是计算贝叶斯公式中的三个概率，只要得到了这三个概率值，显然我们就能通过贝叶斯算法预测分类的结果了。因此，到了这里，我们就知道了朴树贝叶斯算法的核心所在了。
3 朴素贝叶斯中朴素含义
　　 "朴素"含义：本章算法全称叫朴素贝叶斯算法，显然除了贝叶斯准备，朴素一词同样重要。这就是我们要说的条件独立性假设的概念。条件独立性假设是指特征之间的相互独立性假设，所谓独立，是指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系。举个例子来说，假设单词bacon出现在unhealthy后面是与delisious后面的概率相同。当然，我们知道其实并不正确，但这正是朴素一词的含义。同时，朴素贝叶斯另外一个含义是，这些特征同等重要。虽然这些假设都有一定的问题，但是朴素贝叶斯的实际效果却很好。
二、朴素贝叶斯完成文档分类
     朴素贝叶斯的一个非常重要的应用就是文档分类。在文档分类中，整个文档（比如一封电子邮件）是实例，那么邮件中的单词就可以定义为特征。说到这里，我们有两种定义文档特征的方法。一种是词集模型，另外一种是词袋模型。顾名思义，词集模型就是对于一篇文档中出现的每个词，我们不考虑其出现的次数，而只考虑其在文档中是否出现，并将此作为特征；假设我们已经得到了所有文档中出现的词汇列表，那么根据每个词是否出现，就可以将文档转为一个与词汇列表等长的向量。而词袋模型，就是在词集模型的基础上，还要考虑单词在文档中出现的次数，从而考虑文档中某些单词出现多次所包含的信息。
     好了，讲了关于文档分类的特征描述之后，我们就可以开始编代码，实现具体的文本分类了
'''
     
#-------------------------------------------------------从文本中构建词条向量-----------------------------------------------------------------
#1 要从文本中获取特征，需要先拆分文本，这里特征是指来自文本的词条，每个词条是字符的任意组合。词条可以理解为单词，当然也可以是非单词词条，比如URL，IP地址或者其他任意字符串 
# 将文本拆分成词条向量后，将每一个文本片段表示为一个词条向量，值为1表示出现在文档中，值为0表示词条未出现
from numpy import *
def loadDataSet():  #该函数简单不用多说
    postingList = [['my','dog','has','flea',\
                  'problems','help','please'],
                 ['maybe','not','take','him',\
                  'to','dog','park','stupid'],
                 ['my','dalmation','is','so','cute',
                  'I','love','him'],
                 ['stop','posting','stupid','worthless','garbage'],
                 ['my','licks','ate','my','steak','how',\
                  'to','stop','him'],
                 ['quit','buying','worthless','dog','food','stupid']]
    classVec = [0,1,0,1,0,1]
    return postingList, classVec
    
#统计所有文档中出现的词条列表
def createVocabList(dataSet):
    vocabSet=set([])                            #新建一个存放词条的集合
    for document in dataSet:
        vocabSet = vocabSet | set(document)     #将文档列表转为集合的形式，保证每个词条的唯一性.然后与vocabSet取并集（注意并集符号的使用方法），向vocabSet中添加没有出现的新词条
    return list(vocabList)                      #再将集合转化为列表，便于接下来的处理

#根据词条列表中的词条是否在文档中出现(出现1，未出现0)，将文档转化为词条向量 
def setOfWords2Vec(vocabSet,inputSet):
    returnVec=[0]*len(vocabSet) #新建一个长度为vocabSet的列表，并且各维度元素初始化为0（注意学习这种用乘号来扩充列表元素的方法）
    for word in inputSet:   
        if word in vocabSet:    #如果输入的词条在已有的词条列表中出现
            returnVec[vocabSet.index(word)]=1   #通过列表获取当前word在已有的词条列表中的索引(下标)，并将词条向量中的对应下标的项由0改为1
        else:
            print('the word: %s is not in my vocabulary! '%'word')
    return returnVec            #返回inputet转化后的词条向量
    
#需要说明的是，上面函数creatVocabList得到的是所有文档中出现的词汇列表，列表中没有重复的单词，每个词是唯一的。
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
      
     
     
