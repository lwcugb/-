'''
决策树优缺点：
（1）优点:计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。
（2）缺点：可能会产生过度匹配问题。
（3）适用数据类型：数值型和标称型。
决策树的一般流程：
（1）收集数据：可以使用任何方法。
（2）准备数据：树构造算法只适用标称型数据，因此数值型数据必须离散化。
（3）分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
（4）训练算法：构造树的数据结构。
（5）测试算法：使用经验树计算错误率。
（6）使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。
'''

#以下代码的文件命名为tree.py
#--------------------------------------------------------计算数据集的熵--------------------------------------------------------------
from math import log

def calcShannonEnt(dataSet):
    numEntries = len(dataSet)  #获取数据集的行数,dataSet.shape(0)也是获取行数
    labelCounts = {}   #设置字典的数据结构
    for featVec in dataSet:  #注意这种在数组中for循环的方法，featVec表示的是每一行的向量
        currentLabel = featVec[-1]  #获取特征向量的最后一列的标签
        if currentLabel not in labelCounts.keys():  #如果不存在keys()关键字
            labelCounts[currentLabel] = 0     #将当前标签/0键值对存入字典中
        labelCounts[currentLabel]+=1   #否则将当前标签对应的键值加1
    ShannonEnt = 0    #初始化熵为0
    for key in labelCounts:    
        prob = (labelCounts[key])/numEntries   #对于数据集中所有的分类类别，计算各个类别出现的频率
        ShanninEnt -=prob*log(prob,2)      #计算各个类别信息期望值 log(prob,2)表示以2为底的prob的对数
    return ShannonEnt
#可以自己创建一个简单的数据集来验证熵的计算是否正确，数据集中包含两个特征'no surfacing','flippers';数据的类标签有两个'yes','no'
def createDataSet():
    dataSet=[[1,1,'yes'],
            [1,1,'yes'],
            [1,0,'no'],
            [0,1,'no'],
            [0,1,'no']]
    labels=['no surfacing','flippers']
    return dataSet,labels  #返回数据集和类标签
#可以在Python命令提示符下输入以下命令，来检测输出的熵的值是否正确，另外需要说明的是，熵越高，那么混合的数据就越多，如果我们在数据集中添加更多的分类，会导致熵结果增大
#>>>import tree.py
#>>>myDat,label=tree.createDataSet()
#>>>tree.calcShannonEnt(myDat)

#-----------------------------------------------按照某一个特征划分数据集------------------------------------------------------------
def splitDataSet(dataSet,axis,value):    #@dataSet:待划分的数据集 @axis:划分数据集的特征(注意这里输入的列的下标，而不是列) @value:特征的取值
	retDataSet = []   #需要说明的是,python语言传递参数列表时，传递的是列表的引用，如果在函数内部对列表对象进行修改，将会导致列表发生变化，为了不修改原始数据集，创建一个新的列表对象进行操作
	for featVec in dataSet:   #提取数据集的每一行的特征向量
		if featVec[axis] == value:    #如果该特征的取值为value
			reducedFeatVec=featVec[:axis]    #将特征向量的0~axis-1列存入列表reducedFeatVec
			reducedFeatVec.extend(featVec[axis+1:])   #将特征向量的axis+1~最后一列存入列表reducedFeatVec
			#extend()是将另外一个列表中的元素（以列表中元素为对象）添加到当前列表中，构成一个列表。比如a=[1,2,3],b=[4,5,6],则a.extend(b)=[1,2,3,4,5,6]
			#append()是将另外一个列表（以列表为对象）添加到当前列表中。比如a=[1,2,3],b=[4,5,6],则a.extend(b)=[1,2,3,[4,5,6]]
			retDataSet.append(reducedFeatVec)
	return retDataSet
			
			
			
			
			
			
			
			
			



